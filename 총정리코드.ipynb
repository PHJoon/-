{"cells":[{"cell_type":"markdown","metadata":{"id":"OyahUM7mssAL"},"source":["# 1. Colab drive mount"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYbkyUwb2P-5","scrolled":true},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vz6z02UV2Iz8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","from tqdm import tqdm\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import KFold\n","\n","from sklearn.metrics import mean_squared_error\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv1D, ConvLSTM1D, Input, Activation, BatchNormalization, Flatten, LSTM, GRU, SimpleRNN\n","from keras import backend as K\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n","import kerastuner as kt\n","from kerastuner.tuners import RandomSearch\n","from kerastuner.tuners import Hyperband"]},{"cell_type":"markdown","source":["# 2. KNN Imputation"],"metadata":{"id":"06wTyjU8s76-"}},{"cell_type":"code","source":["# 불러오기\n","with open(\"data_자외선/UV_all.pkl\",\"rb\") as fr:\n","    data = pickle.load(fr)"],"metadata":{"id":"2QhkJa6asts3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data2 = data.reset_index()"],"metadata":{"id":"tgxj4IV6tThi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data3 = data2.replace(-999.0, np.nan)"],"metadata":{"id":"iA-PUwE_tTfI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## -999 -> np.nan처리된 데이터를 KNN Imputation"],"metadata":{"id":"8MEO15L3tc1h"}},{"cell_type":"code","source":["# 저장하기\n","with open(\"data_자외선/0616_nan_all.pkl\", \"wb\") as f:\n","    pickle.dump(data3, f)"],"metadata":{"id":"vRVZoe2ltcvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 불러오기\n","with open(\"data_자외선/0616_nan_all.pkl\",\"rb\") as fr:\n","    data = pickle.load(fr)"],"metadata":{"id":"WQP7z3_OtTc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = data[data.date_time < \"2019-09\"]\n","train_data = data[data.date_time >= \"2019-09\"]"],"metadata":{"id":"YTTQ3z3QtTaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data2 = test_data.set_index([\"date_time\"])\n","train_data2 = train_data.set_index([\"date_time\"])"],"metadata":{"id":"VeEyVHFMtTUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 돌리기 전작업 - train\n","df1 = train_data.reset_index().set_index(\"date_time\")\n","df1_uni = df1[\"stn\"].unique()\n","df1_uni"],"metadata":{"id":"8yYH3PmytoUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train KNN Imputation\n","cols = train_data.columns\n","df_all_imp = pd.DataFrame({i:[] for i in cols})\n","df1 = train_data\n","a = 0\n","# 지역별로 뽑아서 따로 KNN imp 실행해주고 concat으로 합쳐서 전체를 만들어준다.\n","for uni in df1_uni: # stn unique값을 순서대로 넣음\n","  df2 = df1.loc[df1[\"stn\"]==uni]\n","  datetime = df2.pop(\"date_time\") # date_time은 imput을 못돌리므로 따로 빼주고 \n","  datetime1 = pd.DataFrame({\"date_time\":datetime}) # dataframe으로 만들어준다\n","  datetime2 = datetime1.reset_index().drop(\"index\", axis=1) # index번호 이상해서 다시 맞춰주고\n","  # KNN imp 실행\n","  imputer = KNNImputer(n_neighbors=4)\n","  imputed = imputer.fit_transform(df2)  \n","  df_imputed = pd.DataFrame(imputed, columns=df2.columns)\n","  # KNN imp로 만들어진 dataframe을 따로빼준 datetime과 결합\n","  df_imputed = pd.concat([df_imputed, datetime2], axis=1)\n","  # df_imputed.info() # 확인용\n","  df_all_imp = pd.concat([df_all_imp, df_imputed], axis=0) # 전체데이터에 마지막으로 추가해주기\n","  # print(df_all_imp[a:a+105264]) # 확인용\n","  # a += 105264 # 한 지역 인덱스 수만큼 확인용\n","  print(uni, \"completed\")"],"metadata":{"id":"cHMAT2VQtoSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장하기\n","with open(\"data_자외선/0616_KNN_imp_train.pkl\",\"wb\") as f:\n","    pickle.dump(df_all_imp, f)"],"metadata":{"id":"_WQTSit3uH5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 돌리기 전작업 - test\n","df1 = test_data.reset_index().set_index(\"date_time\")\n","df1_uni = df1[\"stn\"].unique()\n","df1_uni"],"metadata":{"id":"-26YtGuatoQK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test\n","cols = test_data.columns\n","df_all_imp = pd.DataFrame({i:[] for i in cols})\n","df1 = test_data\n","a = 0\n","# 지역별로 뽑아서 따로 KNN imp 실행해주고 concat으로 합쳐서 전체를 만들어준다.\n","for uni in df1_uni: # stn unique값을 순서대로 넣음\n","  df2 = df1.loc[df1[\"stn\"]==uni]\n","  datetime = df2.pop(\"date_time\") # date_time은 imput을 못돌리므로 따로 빼주고 \n","  datetime1 = pd.DataFrame({\"date_time\":datetime}) # dataframe으로 만들어준다\n","  datetime2 = datetime1.reset_index().drop(\"index\", axis=1) # index번호 이상해서 다시 맞춰주고\n","  # KNN imp 실행\n","  imputer = KNNImputer(n_neighbors=4)\n","  imputed = imputer.fit_transform(df2)  \n","  df_imputed = pd.DataFrame(imputed, columns=df2.columns)\n","  # KNN imp로 만들어진 dataframe을 따로빼준 datetime과 결합\n","  df_imputed = pd.concat([df_imputed, datetime2], axis=1)\n","  # df_imputed.info() # 확인용\n","  df_all_imp = pd.concat([df_all_imp, df_imputed], axis=0) # 전체데이터에 마지막으로 추가해주기\n","  # print(df_all_imp[a:a+105264]) # 확인용\n","  # a += 105264 # 한 지역 인덱스 수만큼 확인용\n","  print(uni, \"completed\")"],"metadata":{"id":"V0KzdezQtoNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장하기\n","with open(\"data_자외선/0616_KNN_imp_test.pkl\",\"wb\") as f:\n","    pickle.dump(df_all_imp, f)"],"metadata":{"id":"NSxViyFqtoLJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Un2XusJmvpel"},"source":["# 3. Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6g7VDF14vdb","scrolled":true},"outputs":[],"source":["# Data 불러오기\n","df = pd.read_pickle(\"/content/drive/MyDrive/날씨/data_자외선/전처리_knn/knn_imp(0616).pkl\")\n","\n","\n","# Time Encoding(month, hour)\n","def encode(data, col, max_val):\n","    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n","    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n","    return data\n","\n","df['month'] = df[\"date_time\"].dt.month\n","df = encode(df, 'month', 12)\n","\n","df['hour'] = df[\"date_time\"].dt.hour\n","df = encode(df, 'hour', 23)\n","\n","# Drop features\n","df.drop(columns=[\"sateza\", \"height\", \"landtype\", \"month\", \"hour\"], inplace=True)\n","\n","# Feature 재정렬\n","df = df[['date_time','stn', 'uv', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos', 'lon', 'lat', \n","        'band1', 'band2', 'band3', 'band4', 'band5',\n","       'band6', 'band7', 'band8', 'band9', 'band10', 'band11', 'band12',\n","       'band13', 'band14', 'band15', 'band16', 'solarza', 'esr']]\n","\n","# 20, 21년 7~9월 Train Data\n","df_train_1 = df.loc[(df[\"date_time\"] >= \"2020-07-01\") & (df[\"date_time\"] < \"2020-10-01\")]\n","df_train_2 = df.loc[(df[\"date_time\"] >= \"2021-07-01\") & (df[\"date_time\"] < \"2021-10-01\")]\n","df_train_789 = pd.concat([df_train_1, df_train_2], axis=0)\n","\n","# 19년 8월 Train Data\n","df_test = df.loc[(df[\"date_time\"] >= \"2019-08-01\") & (df[\"date_time\"] < \"2019-09-01\")]\n","\n","df_train_789.reset_index(drop=True, inplace=True)\n","df_test.reset_index(drop=True, inplace=True)\n","\n","df_train_789.head()"]},{"cell_type":"markdown","metadata":{"id":"eajPd_sTsoB_"},"source":["# 4. Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEKAHCH8fDaW"},"outputs":[],"source":["# df_train_789\n","# Scaling 변수 설정\n","df_train_1= df_train_789.iloc[:, :7]\n","\n","scaler = StandardScaler()\n","df_train_std = df_train_789.iloc[:, 7:]\n","df_train_std = scaler.fit_transform(df_train_std)\n","df_train_std = pd.DataFrame(df_train_std, columns=df_train_789.columns[7:])\n","\n","df_train_789 = pd.concat([df_train_1, df_train_std], axis=1)\n","\n","# df_test\n","df_test_1 = df_test.iloc[:, :7]\n","\n","df_test_std = df_test.iloc[:, 7:]\n","df_test_std = scaler.transform(df_test_std)\n","df_test_std = pd.DataFrame(df_test_std, columns=df_test.columns[7:])\n","\n","df_test = pd.concat([df_test_1, df_test_std], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"VBTgQM0yvuND"},"source":["# 5. Build_Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LC8VUhNhBBVU"},"outputs":[],"source":["# 시계열 데이터를 원하는 길이만큼 묶어주는 함수 \n","def build_dataset(time_series, seq_length):\n","  dataX = []\n","  dataY = []\n","  \n","  for i in tqdm(range(len(time_series) - seq_length)):\n","    x = time_series.iloc[i:i+seq_length, :-1]\n","    y = time_series.iloc[i+seq_length-1, -1]\n","\n","    dataX.append(x)\n","    dataY.append(y)\n","\n","  return np.array(dataX), np.array(dataY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hcDxnsuP3Z3k"},"outputs":[],"source":["# 함수를 사용하기 위해 변수 순서 재정렬\n","df_train_789 = df_train_789[['date_time','stn', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos', \n","        'band1', 'band2', 'band3', 'band4', 'band5',\n","       'band6', 'band7', 'band8', 'band9', 'band10', 'band11', 'band12',\n","       'band13', 'band14', 'band15', 'band16', 'solarza', 'esr', 'uv']]\n","  \n","df_test = df_test[['date_time','stn', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos', \n","        'band1', 'band2', 'band3', 'band4', 'band5', \n","       'band6', 'band7', 'band8', 'band9', 'band10', 'band11', 'band12',\n","       'band13', 'band14', 'band15', 'band16', 'solarza', 'esr', 'uv']]\n","\n","# date_time과 stn은 제외함\n","df_train_789_timeseries = df_train_789.iloc[:, 2:]\n","df_test_timeseries = df_test.iloc[:, 2:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpZaVvMGQEcw"},"outputs":[],"source":["train_789_x, train_789_y = build_dataset(df_train_789_timeseries, 3)\n","test_x, test_y = build_dataset(df_test_timeseries, 3)"]},{"cell_type":"markdown","metadata":{"id":"WICcyyqRv0Rb"},"source":["# 6. Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dGA9N1ivyod"},"outputs":[],"source":["# 학습 시 loss로 쓸 Custom RMSE 함수 \n","def rmse(y_true, y_pred):\n","        return K.sqrt(K.mean(K.square(y_pred - y_true))) "]},{"cell_type":"markdown","metadata":{"id":"rEu2RzQzbSms"},"source":["## 1D CNN"]},{"cell_type":"markdown","metadata":{"id":"NwEN6dVjwcwc"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtVRk5LsBBaO"},"outputs":[],"source":["def set_cnn1d(): # Causal Padding을 사용한 CNN1D 모델 구축함수\n","\n","  nf = 16 \n","  fs = 3 \n","  padding = 'causal'  # Convolution을 진행할 때, 매 step에서 output이 오직 현시점의 input과 과거 시점들의 데이터에만 종속되도록하기 위해서 Causal Padding을 사용\n","  activation = 'relu'\n","\n","  model = Sequential()\n","\n","  model.add(Conv1D(filters = nf, kernel_size = fs, padding = padding, input_shape=(3, 22)))\n","  model.add(BatchNormalization()) # 비선형 성질을 유지 하면서 학습 될 수 있게 해주고, regularization 효과를 가지기 위해 배치정규화 설정\n","  model.add(Activation(activation = activation))\n","\n","  model.add(Conv1D(filters = nf * 2, kernel_size = fs, padding = padding))\n","  model.add(BatchNormalization())  # 비선형 성질을 유지 하면서 학습 될 수 있게 해주고, regularization 효과를 가지기 위해 배치정규화 설정\n","  model.add(Activation(activation = activation))\n","\n","  model.add(Conv1D(filters = nf * 4, kernel_size = fs, padding = padding))\n","  model.add(BatchNormalization())  # 비선형 성질을 유지 하면서 학습 될 수 있게 해주고, regularization 효과를 가지기 위해 배치정규화 설정\n","  model.add(Activation(activation = activation))\n","\n","  # Convolution 연산을 진행한 결과를 다시 Flatten 하여 최종 값(Dense(1)) 도출\n","  model.add(Flatten())\n","\n","  model.add(Dense(32, activation = activation)) \n","  model.add(Dense(8, activation = activation)) \n","  model.add(Dense(1))# output size \n","\n","  optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n","\n","  model.compile(loss = rmse, optimizer = optimizer, metrics=['mae', 'mse'])\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ryjtCuqPBBcU"},"outputs":[],"source":["cnn1d = set_cnn1d()"]},{"cell_type":"markdown","metadata":{"id":"_Yyo47O2wNBT"},"source":["### Model fit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWePOL3ooatj"},"outputs":[],"source":["model_directory = '/content/drive/MyDrive/날씨/박형준/model/'\n","tensorboard_directory = '/content/drive/MyDrive/날씨/박형준/tensorboard/cnn1d/'\n","\n","# Call-back 함수\n","# CheckPoint: Epoch 마다 val_loss를 확인하여, 값이 향상되었을 경우에만 저장\n","CP = ModelCheckpoint(filepath=model_directory+'cnn1d0625_789-{epoch:03d}-{val_loss:.4f}.hdf5',\n","            monitor='val_loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n","\n","# 학습과정 진행사항 확인\n","TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n","\n","# 모델의 개선이 없을 경우 Learning rate 조절\n","LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-7)\n","\n","CALLBACK = [CP, TB, LR]\n","\n","cnn1d.fit(train_789_x, train_789_y, validation_split=0.2, shuffle=True, batch_size=8, callbacks=CALLBACK, epochs=20)"]},{"cell_type":"markdown","metadata":{"id":"4PnEbPhowP5X"},"source":["### Load & Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tE1-7QuXisDU"},"outputs":[],"source":["# loss가 가장 낮은 모델 weight를 가져오기 위해 모델 만들기\n","pretrained_model = set_cnn1d()\n","pretrained_model.load_weights('/content/drive/MyDrive/날씨/박형준/model/cnn1d0625_789-017-0.3714.hdf5')\n","\n","# Create a new model by extracting layers from the original model:\n","extracted_layers = pretrained_model.layers[:]\n","cnn1d = keras.Sequential(extracted_layers)\n","\n","pred = cnn1d.predict(test_x)\n","mean_squared_error(y_true=test_y, y_pred=pred) ** 0.5"]},{"cell_type":"markdown","metadata":{"id":"Rf8zMceGMPAB"},"source":["## CNN-LSTM"]},{"cell_type":"markdown","metadata":{"id":"psHuTD-Zwnh8"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4RdErizMQE4"},"outputs":[],"source":["def set_cnnlstm():\n","\n","  nf = 16 \n","  fs = 3 \n","  padding = 'causal'\n","\n","  model = Sequential()\n","\n","  model.add(Conv1D(filters = nf * 2, kernel_size = fs, padding = padding, input_shape=(3, 22)))\n","  model.add(BatchNormalization())\n","  model.add(Activation(activation = activation))\n","\n","  model.add(Conv1D(filters = nf * 4, kernel_size = fs, padding = padding))\n","  model.add(BatchNormalization())\n","  model.add(Activation(activation = activation))\n","\n","  model.add(LSTM(16, return_sequences=True))\n","  model.add(LSTM(16))\n","  model.add(Dense(1, activation=activation))\n","\n","  optimizer = keras.optimizers.Adam()\n","\n","  model.compile(loss = rmse, optimizer = optimizer, metrics=['mae', 'mse'])\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FwU1gp9NOe8w"},"outputs":[],"source":["cnnlstm = set_cnnlstm()"]},{"cell_type":"markdown","metadata":{"id":"AmXpBhFuw_nz"},"source":["### Model fit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tiuSwn3nOnNv"},"outputs":[],"source":["model_directory = '/content/drive/MyDrive/날씨/박형준/model/'\n","tensorboard_directory = '/content/drive/MyDrive/날씨/박형준/tensorboard/cnnlstm/'\n","\n","# Call-back 함수\n","# CheckPoint: Epoch 마다 val_loss를 확인하여, 값이 향상되었을 경우에만 저장\n","CP = ModelCheckpoint(filepath=model_directory+'cnnlstm0625-{epoch:03d}-{val_loss:.4f}.hdf5',\n","            monitor='val_loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n","\n","# 학습과정 진행사항 확인\n","TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n","\n","# 모델의 개선이 없을 경우 Learning rate 조절\n","LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-7)\n","\n","CALLBACK = [CP, TB, LR]\n","\n","cnnlstm.fit(train_789_x, train_789_y, validation_split=0.2, batch_size=8, callbacks=CALLBACK, epochs=20)"]},{"cell_type":"markdown","metadata":{"id":"fWOMGvLrxBLF"},"source":["### Load & Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IaBqqSeWQICv"},"outputs":[],"source":["# loss가 가장 낮은 모델 weight를 가져오기 위해 모델 만들기\n","pretrained_model = set_cnnlstm()\n","pretrained_model.load_weights('/content/drive/MyDrive/날씨/박형준/model/cnnlstm0625-020-0.3774.hdf5')\n","\n","# Create a new model by extracting layers from the original model:\n","extracted_layers = pretrained_model.layers[:]\n","cnnlstm = keras.Sequential(extracted_layers)\n","\n","pred = cnnlstm.predict(test_x)\n","mean_squared_error(y_true=test_y, y_pred=pred) ** 0.5"]},{"cell_type":"markdown","metadata":{"id":"gVIGxyG1qchM"},"source":["## SimpleRNN"]},{"cell_type":"markdown","metadata":{"id":"rhmH1ZH9qdJw"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDhpj2Uwqr0B"},"outputs":[],"source":["def set_rnn():\n","\n","  model = Sequential()\n","\n","  model.add(SimpleRNN(16, input_shape=(3, 22), return_sequences=True))\n","  model.add(SimpleRNN(16))\n","  model.add(Dense(1, activation='relu'))\n","\n","  optimizer = keras.optimizers.Adam()\n","\n","  model.compile(loss = rmse, optimizer = optimizer, metrics=['mae', 'mse'])\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQrAmLIuqsZo"},"outputs":[],"source":["rnn = set_rnn()"]},{"cell_type":"markdown","metadata":{"id":"n-g12U-OqdUp"},"source":["### Model fit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dZxr5f0q2Ob"},"outputs":[],"source":["model_directory = '/content/drive/MyDrive/날씨/박형준/model/'\n","tensorboard_directory = '/content/drive/MyDrive/날씨/박형준/tensorboard/rnn/'\n","\n","# Call-back 함수\n","# CheckPoint: Epoch 마다 val_loss를 확인하여, 값이 향상되었을 경우에만 저장\n","CP = ModelCheckpoint(filepath=model_directory+'rnn_789-{epoch:03d}-{val_loss:.4f}.hdf5',\n","            monitor='val_loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n","\n","# 학습과정 진행사항 확인\n","TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n","\n","# 모델의 개선이 없을 경우 Learning rate 조절\n","LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-7)\n","\n","CALLBACK = [CP, TB, LR]\n","\n","rnn.fit(train_789_x, train_789_y, batch_size=8, callbacks=CALLBACK, validation_split=0.2, epochs=20)"]},{"cell_type":"markdown","metadata":{"id":"PB3cEYt4qdxF"},"source":["### Load & Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNqHX_eQq-1s"},"outputs":[],"source":["# loss가 가장 낮은 모델 weight를 가져오기 위해 모델 만들기\n","pretrained_model = set_rnn()\n","pretrained_model.load_weights('/content/drive/MyDrive/날씨/박형준/model/rnn_789-019-0.3720.hdf5')\n","\n","# Create a new model by extracting layers from the original model:\n","extracted_layers = pretrained_model.layers[:]\n","rnn = keras.Sequential(extracted_layers)\n","rnn.summary()\n","\n","pred = rnn.predict(test_x)\n","mean_squared_error(y_true=test_y, y_pred=pred) ** 0.5"]},{"cell_type":"markdown","metadata":{"id":"nRs3JUVkWYwk"},"source":["## LSTM"]},{"cell_type":"markdown","metadata":{"id":"CMQ9qvrexHVL"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8b7nadGRuJ3"},"outputs":[],"source":["def set_lstm():\n","\n","  model = Sequential()\n","\n","  model.add(LSTM(64, input_shape=(3, 22), return_sequences=True))\n","  model.add(LSTM(64))\n","  model.add(Dense(1, activation='relu'))\n","\n","  optimizer = keras.optimizers.Adam()\n","\n","  model.compile(loss = rmse, optimizer = optimizer, metrics=['mae', 'mse'])\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"re8eD_SyWv8o"},"outputs":[],"source":["lstm = set_lstm()"]},{"cell_type":"markdown","metadata":{"id":"d3Xh1KkWxLEJ"},"source":["### Model fit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLffs159Wztc"},"outputs":[],"source":["model_directory = '/content/drive/MyDrive/날씨/박형준/model/lstm(64)_batch16/'\n","tensorboard_directory = '/content/drive/MyDrive/날씨/박형준/tensorboard/lstm(64)_batch16/'\n","\n","# Call-back 함수\n","# CheckPoint: Epoch 마다 val_loss를 확인하여, 값이 향상되었을 경우에만 저장\n","CP = ModelCheckpoint(filepath=model_directory+'lstm(64)_batch16-{epoch:03d}-{val_loss:.4f}.hdf5',\n","            monitor='val_loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n","\n","# 학습과정 진행사항 확인\n","TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n","\n","# 모델의 개선이 없을 경우 Learning rate 조절\n","LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-7)\n","\n","CALLBACK = [CP, TB, LR]\n","\n","lstm.fit(train_789_x, train_789_y, batch_size=16, callbacks=CALLBACK, shuffle=True, validation_split=0.2, epochs=20)"]},{"cell_type":"markdown","metadata":{"id":"RR19rX6DxOPy"},"source":["### Load & Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiA9qer2XEl0"},"outputs":[],"source":["# loss가 가장 낮은 모델 weight를 가져오기 위해 모델 만들기\n","pretrained_model = set_lstm()\n","pretrained_model.load_weights('/content/drive/MyDrive/날씨/박형준/model/lstm_789-011-0.3706.hdf5')\n","\n","# Create a new model by extracting layers from the original model:\n","extracted_layers = pretrained_model.layers[:]\n","lstm = keras.Sequential(extracted_layers)\n","\n","pred = lstm.predict(test_x)\n","mean_squared_error(y_true=test_y, y_pred=pred) ** 0.5"]},{"cell_type":"markdown","metadata":{"id":"XmoXTQmygVxV"},"source":["## GRU"]},{"cell_type":"markdown","metadata":{"id":"yGFXn-2pxT3N"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pLcOpVegXDp"},"outputs":[],"source":["def set_gru():\n","\n","  activation = 'relu'\n","\n","  model = Sequential()\n","\n","  model.add(GRU(64, input_shape=(3, 22), return_sequences=True))\n","  model.add(GRU(64))\n","  model.add(Dense(1, activation=activation))\n","\n","  optimizer = keras.optimizers.Adam(learning_rate=0.001)\n","\n","  model.compile(loss = rmse, optimizer = optimizer, metrics=['mae', 'mse'])\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUsIJu8S033S"},"outputs":[],"source":["gru = set_gru()"]},{"cell_type":"markdown","metadata":{"id":"HF5d1YP80vZK"},"source":["### Model fit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzqAFEuZ0t2c"},"outputs":[],"source":["model_directory = '/content/drive/MyDrive/날씨/박형준/model/gru(64)_batch16_epochs150/'\n","tensorboard_directory = '/content/drive/MyDrive/날씨/박형준/tensorboard/gru(64)_batch16_epochs150/'\n","\n","# Call-back 함수\n","# CheckPoint: Epoch 마다 val_loss를 확인하여, 값이 향상되었을 경우에만 저장\n","CP = ModelCheckpoint(filepath=model_directory+'gru(64)_batch16_epochs150-{epoch:03d}-{val_loss:.4f}.hdf5',\n","            monitor='val_loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n","\n","# 학습과정 진행사항 확인\n","TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n","\n","# 모델의 개선이 없을 경우 Learning rate 조절\n","LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-7)\n","\n","CALLBACK = [CP, TB, LR]\n","\n","gru.fit(train_789_x, train_789_y, batch_size=16, callbacks=CALLBACK, shuffle=True, validation_split=0.2, epochs=150)"]},{"cell_type":"markdown","metadata":{"id":"sCxc8J-q0yLs"},"source":["### Load & Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNWUT5oK00Uw"},"outputs":[],"source":["# loss가 가장 낮은 모델 weight를 가져오기 위해 모델 만들기\n","pretrained_model = set_gru()\n","pretrained_model.load_weights('/content/drive/MyDrive/날씨/박형준/model/gru(64)_batch16_epochs150/gru(64)_batch16_epochs200-006-0.3888.hdf5')\n","\n","# Create a new model by extracting layers from the original model:\n","extracted_layers = pretrained_model.layers[:]\n","gru = keras.Sequential(extracted_layers)\n","\n","pred = gru.predict(test_x)\n","mean_squared_error(y_true=test_y, y_pred=pred) ** 0.5"]},{"cell_type":"markdown","metadata":{"id":"dZoNxEA8ugfN"},"source":["# 7. Kerastuner-GRU"]},{"cell_type":"markdown","metadata":{"id":"1XuX96ikRpKq"},"source":["### Tuner(GRU)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uw_0rWavufWD","scrolled":true},"outputs":[],"source":["def build_model(hp):\n","    model = keras.Sequential()\n","\n","    model.add(GRU(units=hp.Int('units', min_value=16, max_value=64, step=8), \n","                  input_shape=(3, 22), return_sequences=True))\n","    model.add(GRU(units=hp.Int('units', min_value=16, max_value=64, step=8)))\n","    model.add(Dense(1, activation='relu'))\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(\n","        # 학습률은 자주 쓰이는 0.01, 0.001, 0.0001 3개의 값 중 탐색\n","            hp.Choice('learning_rate',\n","                      values=[1e-3, 1e-4])),\n","        loss=rmse,\n","        metrics=['mae', 'mse'])\n","    return model\n","\n","# RandomSearch\n","# tuner = RandomSearch(\n","#     build_model, # HyperModel\n","#     objective='val_loss', #  최적화할 하이퍼모델\n","#     max_trials=5,\n","#     executions_per_trial=3, # 각 모델별 학습 회수\n","#     directory='/content/drive/MyDrive/날씨/박형준/kerastuner/gru/', # 사용된 parameter 저장할 폴더\n","#     project_name='gru') # 사용된 parameter 저장할 폴더\n","\n","\n","# Hyperband\n","tuner = kt.Hyperband(\n","        build_model, # HyperModel\n","        objective ='val_loss', #  최적화할 하이퍼모델\n","        max_epochs =10, # 각 모델별 학습 회수\n","        factor = 3,    # 한 번에 훈련할 모델 수 결정 변수\n","        directory ='/content/drive/MyDrive/날씨/박형준/kerastuner/gru_1/', # 사용된 parameter 저장할 폴더\n","        project_name ='gru_1') # 사용된 parameter 저장할 폴더\n","      \n","# 출처: https://iyk2h.tistory.com/145 [하루 2시간:티스토리]"]},{"cell_type":"markdown","metadata":{"id":"ZAPKQIPFsoCH"},"source":["### Tuner search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hLZt5Vbyqr4","scrolled":true},"outputs":[],"source":["tuner.search(train_789_x, train_789_y,\n","             epochs=3,\n","             validation_split=0.2, batch_size=8)"]},{"cell_type":"markdown","metadata":{"id":"I1geubUNsoCH"},"source":["### Get best model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnXVT3VCyqgp"},"outputs":[],"source":["models = tuner.get_best_models ( num_models = 2 )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bi5vhAbfyqSB"},"outputs":[],"source":["tuner.results_summary ()"]},{"cell_type":"markdown","metadata":{"id":"pfrUg3Te9oKk"},"source":["# 8. Submission\n","- 처음 값 0으로 채우기\n","- label값 재정렬 해야함(시간순 다음 ,stn순)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQmf1me19p4z","scrolled":true},"outputs":[],"source":["df_sub = pd.read_csv(\"/content/drive/MyDrive/날씨/박형준/1-1_검증데이터셋.csv\")\n","df_sub.set_index(['YearMonthDayHourMinute', 'STN'], inplace=True)\n","df_sub.sort_index(level='STN', inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"vZwA-W_OsoCI"},"source":["### Best pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYt9-Yn-55Fz"},"outputs":[],"source":["pred = gru.predict(test_x)\n","df_pred = pd.DataFrame(pred)\n","\n","# 시계열 데이터 length만큼 앞에 빈 예측값은 채워줌\n","df_sub[\"UV\"][2:] = df_pred[0]\n","df_sub[\"UV\"][:2] = 0\n","\n","df_sub.reset_index(inplace=True)\n","df_sub.sort_values(by=['YearMonthDayHourMinute', 'STN'], inplace=True)\n","df_sub.reset_index(drop=True, inplace=True)\n","df_sub"]},{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1656377047495,"user":{"displayName":"형준","userId":"07119426239817231574"},"user_tz":-540},"id":"Wr7R4F378mzj","outputId":"40e30a9e-9c67-4d9d-99c3-f13c070207e3"},"source":["### To_csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_VDe6DGf9DDH"},"outputs":[],"source":["df_sub.to_csv(\"/content/drive/MyDrive/날씨/박형준/submission.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"총정리코드.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}